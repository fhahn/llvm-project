; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; REQUIRES: aarch64-registered-target
; RUN: opt -passes='lower-matrix-intrinsics' -mtriple=arm64-apple-iphoneos -S < %s | FileCheck %s

declare void @llvm.matrix.column.major.store.v8i64(<8 x i64>, ptr, i64, i1, i32, i32)
declare <8 x i64> @llvm.matrix.column.major.load.v8i64(ptr, i64, i1, i32, i32)

define <8 x i64> @builtin_column_major_load_stride_eq_rows_i64_v8_(ptr %dst) {
  %res = call <8 x i64> @llvm.matrix.column.major.load.v8i64(ptr %dst, i64 4, i1 false, i32 2, i32 4)
  ret <8 x i64> %res
}

define void @builtin_column_major_store_stride_eq_rows_i64_v8_(<8 x i64> %a, ptr %dst) {
  call void @llvm.matrix.column.major.store.v8i64(<8 x i64> %a, ptr %dst, i64 8, i1 false, i32 2, i32 4)
  ret void
}

define void @builtin_column_major_store_stride_lt_rows_i64_v8_(<8 x i64> %a, ptr %dst) {
  call void @llvm.matrix.column.major.store.v8i64(<8 x i64> %a, ptr %dst, i64 7, i1 false, i32 2, i32 4)
  ret void
}

define void @builtin_column_major_store_stride_gt_rows_i64_v8_(<8 x i64> %a, ptr %dst) {
  call void @llvm.matrix.column.major.store.v8i64(<8 x i64> %a, ptr %dst, i64 9, i1 false, i32 2, i32 4)
  ret void
}

